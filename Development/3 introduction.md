# Vitis 加速环境简介

Vitis 软件是一个将Xilinx软件开发的各个方面结合到一个统一环境中的新工具。
Vitis软件平台既支持Vitis嵌入式软件开发流程，也支持Vitis应用程序加速开发流程。

+ Vitis嵌入式软件开发流程是为希望使用下一代技术的Xilinx软件开发工具包(SDK)用户设计的，
+ Vitis应用程序加速开发流程是为希望使用最新的Xilinx FPGA软件加速开发流程的软件开发人员设计的。

该章主要涉及应用程序加速流，以及Vitis核心开发工具包和Xilinx运行时(XRT)的使用。

Vitis应用程序加速开发流程为使用软件和硬件组件的标准编程语言开发
和交付FPGA加速应用程序提供了一个框架。

软件组件或主机程序是使用C/ c++开发的，可以在x86或嵌入式处理器上运行，
并使用OpenCL API调用来管理与加速器的运行时交互。
可以使用C/ c++、OpenCL C或RTL开发硬件组件或内核。


下图是Vitis软件平台示意图。

![image](https://user-images.githubusercontent.com/49140300/188270342-0760d5ac-6879-48fc-bbb2-3fa829e3cd6e.png)

如图所示，Vitis 统一软件平台包含以下功能和元素：

+ Vitis技术的目标是加速硬件平台，
例如Alveo™数据中心加速器卡或Zynq®UltraScale +™MPSoC和基于Zynq®-7000SoC的嵌入式处理器平台。

+ XRT为宿主程序提供了API和驱动程序，以使其与目标平台连接，并处理宿主程序和加速内核之间的事务。

+ Vitis核心开发套件提供了软件开发工具堆栈（例如编译器和交叉编译器），用于构建主机程序和内核代码；分析器（可让您分析和分析应用程序的性能）；调试器（可帮助您定位和修复任何问题）您的应用程序中的问题。
Vitis加速库通过最少的代码更改提供性能优化的FPGA加速，
无需重新实现算法即可利用Xilinx自适应计算的优势。

[Vitis加速库](https://xilinx.github.io/Vitis_Libraries/)
可用于数学，统计，线性代数和DSP的常用功能，
也可用于特定领域的应用程序，例如视觉和图像处理，定量财务，数据库，数据分析和数据压缩。


## 3.2 FPGA加速

与传统的CPU / GPU加速相比，Xilinx FPGA具有许多优势，
包括能够实现可在处理器上运行的任何功能的自定义架构，从而以较低的功耗实现了更好的性能。
与处理器体系结构相比，在Xilinx器件中包含可编程逻辑（PL）架构的结构在应用程序执行中
实现了高度的并行性。

为了在Xilinx器件上实现软件加速的优势，可以考虑在硬件中加速应用程序的大型计算密集型部分。
在自定义硬件中实现这些功能可以使性能和功耗达到理想的平衡。

$\color{#FF3030}{如何构建具有最佳性能的应用程序?}$

## 3.3 系统模型

在Vitis核心开发套件中，应用程序在主机应用程序和硬件加速的内核之间分割，
并在它们之间建立通信通道。

![image](https://user-images.githubusercontent.com/49140300/188271123-8dd402f8-e911-4a7d-b3ea-f5cd1c1c6c16.png)

1. 使用C/C++编写并使用API抽象（例如OpenCL）的**软件程序**在主机处理器（例如x86服务器或用于嵌入式平台的Arm处理器）上运行.

2. **硬件加速**的内核则在主机的可编程逻辑（PL）区域内运行。

3. 由**XRT**管理的API调用用于处理主机程序和硬件加速器之间的事务。

4. 主机和内核之间的**通信**（包括控制和数据传输）通过PCIe®总线或嵌入式平台的AXI总线进行。

5. 控制信息在硬件中的特定**内存**位置之间传输，全局内存用于在主机程序和内核之间传输数据。
(主机处理器和硬件加速器均可访问全局内存，而主机应用程序只能访问主机内存)

>数据传输造成的延迟：
>
>在典型的应用程序中，主机首先将要由内核操作的数据从主机内存传输到全局内存。内核随后对数据进行操作，将结果存储回全局内存中。内核完成后，主机将结果传输回主机内存。主机和全局内存之间的数据传输会引入延迟，这可能会给整个应用程序带来巨大的成本。
>
>**为了在实际系统中实现加速，硬件加速内核所获得的好处必须超过数据传输所增加的延迟。**



目标平台包含FPGA加速内核，全局存储器以及用于存储器传输的直接存储器访问（DMA）。内核可以具有一个或多个全局存储器接口，并且是可编程的。

执行模型可以分解为以下步骤：

1. 主机程序通过嵌入式平台上的AXI总线（通过Alveo数据中心加速器卡上的PCIe接口），将内核所需的数据写入连接的设备的全局存储器中。
2. 主机程序使用其输入参数设置内核。
3. 主机程序触发FPGA上内核功能的执行。
4. 内核根据需要执行所需的计算，同时从全局内存中读取数据。
5. 内核将数据写回到全局内存，并通知主机它已完成任务。
6. 主机程序将数据从全局存储器读回主机存储器，并根据需要继续处理。
FPGA可以在加速器上容纳多个内核实例，不同类型的内核以及同一内核的多个实例。XRT透明地协调了主机程序和加速器中内核之间的交互。Xilinx Github存储库上提供了[XRT体系结构文档](https：//xilinx.github.io/XRT/)

## 3.4 建立过程

Vitis的核心开发工具包提供了所有标准的软件开发环境的特点：

+ 在x86或Arm®处理器上运行的主机应用程序的编译器或交叉编译器。
+ 交叉编译器，用于构建FPGA二进制文件。
+ 调试环境可帮助识别和解决代码中的问题。
+ 性能分析器可识别瓶颈并帮助您优化应用程序。

**主机程序**是使用GNU C++编译器（g++）或GNU C++ Arm交叉编译器为基于MPSoC的设备构建的。

**FPGA二进制文件**是使用Vitis编译器构建的。

### 3.4.1 主机程序构建过程

主应用程序g++通过以下两步过程进行编译并与编译器链接：

1. 将任何所需的代码编译到目标文件（.o）中。
2. 将对象文件（.o）与XRT共享库链接以创建可执行文件。


### 3.4.2 FPGA二进制构建过程

![image](https://user-images.githubusercontent.com/49140300/188272539-0fa626e1-9308-4767-ae18-1030a13455a9.png)

内核可以用C/C ++或OpenCL C代码描述，也可以从打包的RTL设计中创建。如上图所示，每个硬件内核都独立编译为Xilinx目标（.xo）文件。

Xilinx对象（.xo）文件与硬件平台链接，以创建FPGA二进制文件（.xclbin），该文件已加载到目标平台上的Xilinx设备中。

构建FPGA二进制文件的关键是确定要生成的构建目标，有关构建过程的详细说明，参见构建FPGA二进制文件。

## 3.5 建立目标

Vitis编译器生成过程生成主机程序可执行文件（.o）和FPGA二进制（.xclbin）。

+ 当构建目标是软件或硬件仿真时，Vitis编译器会生成FPGA二进制文件中内核的仿真模型。这些仿真目标可以在相对较快的周期内构建，运行和迭代设计。用于调试应用程序并评估性能。
+ 当构建目标是硬件系统时，Vitis编译器使用Vivado Design Suite运行综合和实现，从而为硬件加速器生成.xclbin 。

Vitis编译器提供了三种不同的构建目标，用于调试和验证目的的两个仿真目标，用来产生实际的FPGA二进制文件的默认硬件目标：

+ 软件仿真（sw_emu）

主机应用程序代码和内核代码都被编译为在主机处理器上运行。这样可以通过快速的构建和运行循环来优化迭代算法。该目标对于识别语法错误，对与应用程序一起运行的内核代码执行源代码级调试以及验证系统的行为很有用。

+ 硬件仿真（hw_emu）

内核代码被编译成硬件模型（RTL），该模型在专用模拟器中运行。这种构建和运行循环需要更长的时间，但可以提供详细的，周期精确的内核活动视图。该目标对于测试将在FPGA中使用的逻辑功能以及获得初始性能估计非常有用。

+ 系统（hw）

内核代码被编译成硬件模型（RTL），然后在FPGA上实现，从而产生可以在实际FPGA上运行的二进制文件。


## 3.6 使用Vitis软件平台加速应用程序的方法论
### 3.6.1 方法论概述

1. 构建应用

在第一阶段，开发者制定出有关应用架构的关键决策，包括决定应映射到器件内核的软件函数、所需的并行度及其交付方式。

2. 开发 C/C++ 内核

在第二阶段，开发者实现内核。这主要涉及构建源代码并应用所需的编译器编译指示来创建所需的内核架构并满足性能目标。

![image](https://user-images.githubusercontent.com/49140300/188273088-88ca7c61-42d0-469b-bb7c-44785435563c.png)

性能最优化是一个迭代过程。加速应用程序的初始版本可能无法产生最佳结果。该方法论是一个涉及持续性能分析和重复更改实现的方方面面的过程。

涉及领域：
+ vitis开发工具的使用
+ 应用域
+ 软件加速原理
+ 器件的概念、特性和架构
+ 目标器件加速器卡和对应目标平台的功能特性
+ [硬件实现中的并行度](http://kastner.ucsd.edu/hlsbook/)


### 3.6.2 不同计算单元的区别

>CPU，GPU和可编程设备之间存在明显差异。了解这些差异是有效开发每种设备的应用程序并实现最佳加速的关键。
>
>CPU和GPU均具有预定义的体系结构，具有固定数量的内核，固定指令集和刚性内存体系结构。GPU通过内核数量和采用SIMD/SIMT并行性来扩展性能。相反，可编程设备是完全可定制的体系结构。开发人员创建针对应用程序需求进行了优化的计算单元。通过创建深度流水线化的数据路径来实现性能，而不是乘以计算单元的数量。
>
>可以将CPU视为一组研讨会，每个研讨会都雇用一名非常熟练的工人。这些工人可以使用通用工具，使他们可以构建几乎所有东西。每个工人一次制作一件商品，先后使用不同的工具将原材料变成成品。此顺序转换过程可能需要许多步骤，具体取决于任务的性质。讲习班是独立的，工人都可以完成不同的任务，而不会分散注意力或出现协调问题。
>
>GPU也有车间和工人，但其中有很多，工人也更专业。他们只能访问特定的工具，只能做更少的事情，但是他们做得非常有效。当GPU工人重复执行相同的几个任务，并且所有人都同时执行相同的事情时，它们的功能最佳。毕竟，在有这么多不同的工人的情况下，给他们所有相同的订单会更有效率。
>
>可编程设备FPGA使这个车间类似于工业时代。如果CPU和GPU是一组单独的工人，并采取顺序步骤将输入转换为输出，则可编程设备是具有装配线和传送带的工厂。沿组装线分派的工人将原材料逐步转变为制成品。每个工人重复执行相同的任务，并且部分成品在传送带上从一个工人转移到另一个工人。这导致更高的生产吞吐量。
>
>可编程设备FPGA的另一个主要区别是工厂和装配线不存在，这与CPU和GPU的车间和工人不同。为了完善我们的类比，可编程设备就像是一批待开发的空批。这意味着设备开发人员可以建立工厂，装配线和工作站，然后针对所需任务自定义它们，而不必使用通用工具。就像批量一样，设备的房地产也不是无限的，这限制了可以在设备中建立工厂的数量和规模。因此，正确设计和配置这些工厂是设备编程过程的关键部分。
>
>传统的软件开发是关于在预定义的体系结构上进行编程的功能。可编程设备开发是关于对体系结构进行编程以实现所需功能。

### 3.6.3 设计设备加速应用程序的方法

在开始开发加速应用程序之前，正确地架构它很重要。在此阶段，开发人员将对应用程序的体系结构做出关键决策，并确定诸如应将哪些软件功能映射到设备内核，需要多少并行性以及如何交付并行化等因素。


![image](https://user-images.githubusercontent.com/49140300/188273154-f7f4e98b-c71d-446d-8e8d-f673a8cc81cc.png)


步骤1：建立基准应用程序性能并建立目标

>首测量运行时和吞吐量性能，以识别现有平台上当前正在运行的应用的瓶颈。
>
>获取整个应用程序（端到端）以及应用程序中的每个主要函数生成这些性能数据，最有效的方法是使用剖析工具（如 valgrind、callgrind 和 GNU gprof）来运行应用。这些工具生成的剖析数据可显示调用图形，包括所有函数的调用次数及其执行时间。这些数据能够为大部分后续分析进程确立基线。
>
>耗用执行时间最多的函数适合卸载到 FPGA 上并在其中进行加速。
>
>**测量运行时间**
>
>测量运行时间是软件开发的标准做法。这可以使用常见的软件分析工具（如 gprof）来完成，也可以使用定时器和性能计数器检测代码来完成。
>
>**测量吞吐量**
>
>吞吐量是处理数据的速率。要计算给定函数的吞吐量，请将函数处理的数据量除以函数的运行时间。
>
>TSW = max(V_INPUT, V_OUTPUT)/Running Time
>
>某些函数处理的数据量是预先确定的。在此情况下，可以使用简单的代码检查来确定此数据量。在某些其它情况下，数据量是可变的。在此情况下，使用计数器检测应用程序代码以动态测量数据量非常有用。
>
>测量吞吐量与测量运行时间一样重要。虽然器件内核可以缩短整体运行时间，但它们对于应用吞吐量的影响更大。因此，将吞吐量视为主要最优化目标非常重要。
>
>**确定最大吞吐量**
>
>在大多数器件加速系统中，可达到的最大吞吐量受到AXI总线的限制。AXI总性能则会受到诸多不同方面的影响，例如，主板、驱动程序、目标平台和传输大小等。预先运行 DMA 测试以测量AXI传输的有效吞吐量，从而确定加速潜力的上限。
>

步骤2：确定加速目标和功能
>
>**确立总体加速目标**
>
>在开发早期确定加速目标是必要的，因为加速目标和基线性能之间的比率将推动分析和决策过程。
>
>加速目标可以是硬目标或软目标。例如，实时视频应用程序可能有每秒处理 60 帧的硬性要求。数据科学应用程序则可能有比其它实现快 10 倍的软目标。
>
>无论哪种方式，领域专业知识对于设置可实现且有意义的加速目标都是很重要的。
>
>**确定要加速的函数**
>
>最大程度减少对现有代码的更改，以便能够在 FPGA 上快速生成有效的设计，并获取基线性能和资源数值。
>
>选择要在硬件中加速的函数时，有两方面需要考量：
>
>**性能瓶颈**
>
>应用程序最常调用哪些函数？
>
>在纯顺序应用中，通过查看剖析报告即可轻松识别性能瓶颈。但是，大多数真实应用均为多线程应用，在寻找性能瓶颈时考虑并行度的影响非常重要。在寻找加速对象时，请考虑整个应用程序的性能，而不仅仅考虑单个函数。
>
>**加速潜力**
>
>这些函数是否具有加速潜力？
>
>属于软件应用瓶颈的函数并不一定能在器件中运行得更快。通常需要详细分析来准确判定给定函数的实际加速潜力。但是，可以根据一些简单的准则来评估函数是否具有硬件加速的潜力：
>
>>该函数的计算复杂度是多少？
>>
>>计算复杂度表示执行函数所需的基本计算的运算数量。在可编程器件中，加速是通过创建高度并行且深度流水打拍的数据路径来实现的。这就像是先前类比中的组装线。组装线越长，包含的工作站越多，则与车间内工人采用顺序步骤相比，就更高效。
>>
>>所谓适合加速的函数，表示在此类函数中需要对每个输入样本按顺序执行一连串深度运算才能生成输出样本。
>
>>该函数的计算密集度是多少？
>>
>>函数的计算密集度是运算总数占输入和输出数据总量的比例。计算密集度较高的函数更适合用于加速，因为将数据移植到加速器的开销相对较低。
>
>>什么是函数的数据访问局部性剖析？
>>
>>数据复用、空间局部性和时间局部性的概念对于评估将数据移植到加速器的开销的可优化程度很有用。空间局部性反映了多个连续存储器访问操作之间的平均距离。时间局部性反映了程序执行期间任一地址的访问操作的平均数量。这些测量值越低越好，因为这样数据更便于缓存在加速器中，从而降低了对全局存储器进行代价不菲且可能冗余的访问的需求。
>
>>函数吞吐量与器件中可达到的最大吞吐量相比如何？
>>
>>器件加速的应用属于分布式多进程系统。总体应用的吞吐量不会超过其最慢的函数的吞吐量。这种瓶颈的本质因应用而异，可能源于系统的任何方面：I/O、计算或数据迁移。开发者可以通过将最慢的函数的吞吐量除以选定函数的吞吐量来确定最大加速潜力。
>>
>>最大加速潜力 = TMin / TSW
>>在 MPSoC嵌入式平台上，AXI总线会对数据传输施加吞吐量限制。虽然此限制可能并非应用的真正瓶颈，但可能确立上限，从而用于早期估算。例如，假设 AXI吞吐量为 10 GB/s 且软件吞吐量为 50 MB/s，那么此函数的最大加速因数为 200x。
>
步骤3：确定设备并行化需求
>
>识别要加速的函数并明确总体加速目标之后，下一步是确定满足目标所需的并行化级别。
>
>组装线允许逐步处理输入和同步处理输入。在硬件中，这种并行化操作称为流水打拍。组装线上的工作站数量对应于硬件流水线中的阶数。
>
>内核内部的另一个并行维度是同时处理多个样本的能力。这就像在输送带上同时放置不只一个样本，而是多个样本。为了适应这种需求，需定制组装线工作站以并行处理多个样本。这样即可有效定义内核中的数据路径的宽度。
>
>通过增加组装线的数量可以进一步扩展性能。这可以通过在工厂中布置多条组装线来实现，也可以通过构建多个相同的工厂并在每个工厂中布置一条或多条组装线来实现。
>
>>**估算无并行化情况下的硬件吞吐量**
>>
>>THW = Frequency/Computational Intensity = Frequency*max(V_INPUT, V_OUTPUT)/V_OPS
>>
>>函数的计算密集度是运算总数占输入和输出数据总量的比例, 以上公式清晰表明了含大量运算和少量数据的功能更适合用于加速。
>
>>**确定所需的并行度**
>>
>>Speed-up = T_HW/T_SW = Fmax*Running Time/V_ops
>>
>>在没有任何并行化的情况下，初始速度很有可能小于 1。
>
>>**计算满足性能目标所需的并行度**
>>
>>Parallelism Needed = T_Goal/T_HW = T_Goal*V_ops/(F_max*max(V_INPUT, V_OUTPUT))
>>
>>这种并行度可以通过各种方式实现：拓宽数据路径、使用多个引擎，以及使用多个内核实例，应根据特定需求及其应用特征来判定最佳组合。
>
>>**确定数据路径应并行处理的样本数量**
>>
>>一种可能性是通过创建更宽的数据路径和并行处理更多样本来加速计算。某些算法很适合这种方法，而其它算法则不然。重要的是要了解算法的性质以确定此方法是否有效，如果可行，则应确定为满足性能目标而需要并行处理的样本数量。
>>
>>使用更宽的数据路径并行处理更多样本可减少加速函数的时延（运行时间），从而提高性能。
>
>>**确定器件中可以例化和应该例化的内核数量**
>>
>>如果数据路径无法并行化（或无法充分并行化），考虑[添加更多内核实例](https://github.com/Xilinx/Vitis-Tutorials/tree/2021.1/Hardware_Acceleration/Feature_Tutorials/05-using-multiple-cu)（多个计算单元 (CU)）。
>>
>>添加更多内核实例可允许对目标函数并行执行更多次调用，从而提升应用性能，如下所示。多个数据集将由不同的实例同时处理。应用性能与实例数量呈线性关系，前提是主机应用可以使内核保持忙碌。
>>

步骤4：确定软件应用程序并行化需求
>
>>虽然硬件器件及其内核旨在提供潜在的并行化，但必须合理设计软件应用以利用这种潜在的并行化。
>>
>>软件应用中的并行化表示主机应用程序执行下列操作的能力：
>>
>>+ 在器件内核运行时，最大程度减少空闲时间并执行其它任务。
>>+ 使器件内核保持处于活动状态，以便尽早并尽量频繁执行新计算。
>>+ 最优化往来器件的数据传输。
>
>>**在运行器件内核时最大程度减少 CPU 空闲时间**
>>
>>所谓器件加速，即将某些计算从主处理器卸载到器件中的内核。在纯顺序模型中，应用将保持空闲，并等待结果就绪，然后才恢复处理。
>>
>>设计软件应用程序时应避免这种空闲周期。首先确定不依赖于内核结果的应用程序部分。然后构造应用程序，以便这些函数可以在主机上与器件中运行的内核并行执行。
>
>>**使器件内核始终保持在使用中状态**
>>
>>内核可能存在于器件中，但仅在应用请求时，内核才会运行。为了尽可能提高性能，请将应用设计为使内核保持繁忙。
>>从概念上讲，这是通过在当前请求完成之前发出后续请求来实现的。这将导致流水打拍和重叠执行，从而以最优方式使用内核。
>
>>**对往来器件的数据传输进行最优化**
>>在加速应用中，数据必须从主机传输到器件，在基于PCIe的应用案例中尤其如此。这样会产生时延，时延对于应用的总体性能来说可能代价高昂。
>>
>>+ 数据需在正确的时间进行传输，否则如果内核必须等待数据变为可用，就会对应用性能造成负面影响。因此，在内核需要之前传输数据非常重要。这是通过将数据传输与内核执行重叠来实现的，如 使器件内核始终保持在使用中状态 中所述。如前图中的顺序所示，此方法支持隐藏数据传输的时延开销，并避免出现内核不得不等待数据就绪的状况。
>>
>>+ 最优化数据传输的另一种方法是传输最佳大小的缓冲器。
>>根据传输的缓冲器大小，PCIe 的有效吞吐量差异巨大。缓冲器越大，吞吐量越大，因此就更能确保加速器始终具有操作数据并且不浪费周期。通常，传输的数据最好不少于 1 MB。提前运行 DMA 测试对于找到最佳缓冲器大小非常有用。并且，在确定最佳缓冲器大小时，请考虑缓冲器过大对于资源利用率和传输时延的影响。
>
>>**将目标应用时间线概念化**
>>
>>Vitis 软件平台可基于实际应用运行来生成时间线视图。如果开发者有自己预测的目标时间线，可将其与实际结果进行比较，识别潜在问题，并基于最优结果进行迭代和收敛。
>
>相关细节见[UG1393](https://docs.xilinx.com/r/2021.2-Chinese/ug1393-vitis-application-acceleration/%E5%B0%86%E7%9B%AE%E6%A0%87%E5%BA%94%E7%94%A8%E6%97%B6%E9%97%B4%E7%BA%BF%E6%A6%82%E5%BF%B5%E5%8C%96)
>
步骤5：细化架构细节
>
>在继续开发应用程序及其内核之前，最后要做的是根据到目前为止做出的顶层决策来优化和推导二级架构细节。
>
>>**完成内核边界**
>>如前所述，可以通过创建多个内核实例（计算单元）来提高性能。但是，添加 CU 存在 I/O 端口、带宽和资源方面的成本。
>>
>>在 Vitis 软件平台流程中，内核端口最大位宽为 512 位（64 个字节），并存在器件资源方面的固定成本。最重要的是，目标平台给可供使用的端口最大数量设置了限制。
>>
>>利用多个计算单元进行扩展的另一种方法是通过在内核内部添加多个引擎来进行扩展。这种方法能够以添加更多 CU 相同的方式来提升性能：即，由内核内部的不同引擎来并发处理多个数据集。
>>
>>将多个引擎置于单个内核中还能够减少连接到全局存储器的需仲裁的端口数量和传输事务数量，从而提升有效带宽。另一方面，这种变换需要对内核内部的显式 I/O 多路复用行为进行编码。
>
>>**确定内核布局和连接**
>>
>>最终确定内核边界后，开发者即可明确要例化的内核数量，以及需要连接到全局存储器资源的端口数量。
>>
>>了解目标平台的功能以及可用的全局存储器资源就显得至关重要。例如， Alveo™ U200 数据中心加速器卡具有 4 x 16 GB 的 DDR4 存储体和 3 x 128 KB 的 PLRAM 存储体，分布在 3 个超级逻辑区域 (SLR) 内。
>>
>>如果把内核比作工厂，那么全局存储体就是货物进出工厂的仓库。SLR 类似于独立的工业区，其中已存在仓库，并且可建造工厂。虽然可以将货物从一个区域的仓库转移到另一个区域的工厂，但这可能会增加延迟和复杂性。
>>
>>使用多个 DDR 有助于平衡数据传输负载并提高性能。但是，这附带有成本，因为每个 DDR 控制器都会占用器件资源。在决定如何将内核端口连接到存储体时，需权衡考虑这些注意事项。
>>

3.6.4 开发C / C ++内核的方法论

Vitis 软件平台支持以 C/C++ 或 RTL（Verilog、VHDL 或 System Verilog）建模的内核。此方法指南适用于 C/C++ 内核。如需了解有关开发 RTL 内核的详细信息，请参阅[RTL 内核](https://docs.xilinx.com/r/2021.2-Chinese/ug1393-vitis-application-acceleration/RTL-%E5%86%85%E6%A0%B8)。

**关键内核要求**

+ 吞吐量目标
+ 时延目标
+ 数据路径宽度
+ 引擎数
+ 接口带宽

![image](https://user-images.githubusercontent.com/49140300/188275226-90107ae8-d3a5-4726-8adb-0c68ef78c916.png)


关于高级综合编译器

在开始内核开发过程之前，需熟悉高级综合（HLS）概念。HLS编译器将C/C ++代码转换为RTL设计，然后将其映射到设备结构上。

HLS编译器比标准软件编译器更具限制性。例如，存在不支持的构造，包括：系统函数调用，动态内存分配和递归函数。

C/C ++源代码的结构会对所生成的硬件实现的性能产生重大影响。方法论将帮助构建代码，以满足应用程序吞吐量的目标。

步骤1：将代码划分为负载-计算-存储模式
>
>创建带有下列元素的顶层函数：
>
>+ 与所需内核接口匹配的接口参数。
>+ 三个子函数：加载、计算和存储。
>+ 本地阵列或 hls::stream 变量，用于在这些函数之间传递数据。
>
>![image](https://user-images.githubusercontent.com/49140300/188275277-5ef38af2-0b22-415e-9cd7-ca347317bd95.png)
>

步骤2：将计算块划分为较小的函数

步骤3：确定需要优化的循环

步骤4：改善循环延迟

步骤5：提高环路吞吐量
